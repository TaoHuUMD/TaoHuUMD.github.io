<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="	
        HVTR++: Image and Pose Driven Human Avatars using Hybrid Volumetric-Textural Rendering.">
  <title>	
    HVTR++: Image and Pose Driven Human Avatars using Hybrid Volumetric-Textural Rendering</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');



  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <style type="text/css">
    #div1{
      width: 100%;
      height: 100%;
      border:#000 solid 0px;
      margin: 50px auto;
      /* overflow: hidden; */
    }
    #div1 img{
      cursor: pointer;
      transition: all 0.6s;
    }
    #div1 img:hover{
      transform: scale(1.6);
    }

    #div1 iframe{
      cursor: pointer;
      transition: all 0.6s;
    }
    #div1 iframe:hover{
      transform: scale(1.4);
    }
    </style>


</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          	

          <h1 class="title is-1 publication-title">HVTR++: </br> Image and Pose Driven Human Avatars using Hybrid Volumetric-Textural Rendering</h1>
          <h3 class="title is-3 publication-title"> <a href="https://ieeexplore.ieee.org/document/10190111" target=&ldquo;blank&rdquo;>IEEE Transactions on Visualization and Computer Graphics 2023 </a></h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">              
              <a href="https://taohuumd.github.io/" target=&ldquo;blank&rdquo;>Tao Hu</a><sup>1</sup>,</span> &nbsp;&nbsp;
            <span class="author-block">
              <a href="https://hongyixu37.github.io/homepage/" target=&ldquo;blank&rdquo;>Hongyi Xu</a><sup>2</sup>,</span>&nbsp;&nbsp;
            <span class="author-block">
              <a href="http://linjieluo.com/" target=&ldquo;blank&rdquo;>Linjie Luo</a><sup>2</sup>,</span>&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://ytrock.com/" target=&ldquo;blank&rdquo;>Tao Yu</a>
              <sup>3</sup>,</span>&nbsp;&nbsp;
            <span class="author-block">
              Zerong Zheng<sup>3</sup>,
            </span>&nbsp;&nbsp;
            <span class="author-block">
              He Zhang<sup>3</sup>,
            </span>&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://liuyebin.com/" target=&ldquo;blank&rdquo;>Yebin Liu</a><sup>3</sup>,
            </span>&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://www.cs.umd.edu/~zwicker/" target=&ldquo;blank&rdquo;>Matthias Zwicker</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Maryland, College Park</span> &nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>ByteDance AI Lab</span> &nbsp;&nbsp;&nbsp;&nbsp;
			<span class="author-block"><sup>3</sup>Tsinghua University</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://1drv.ms/b/s!Att91f8pjJXNmz7zi95OqPloJL6E?e=fMzG8U"
                   class="external-link button is-normal is-rounded is-dark" target=&ldquo;blank&rdquo;>
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

			  <span class="link-block">
                <a href="https://www.youtube.com/watch?v=RdKLfRYtg3I"                class="external-link button is-normal is-rounded is-dark", target=&ldquo;blank&rdquo;>
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
             
              <span class="link-block">
                <a href="https://github.com/TaoHuUMD/SurMo"
                   class="external-link button is-normal is-rounded is-dark", target=&ldquo;blank&rdquo;>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
             </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="subtitle has-text-centered">
          <b>TL;DR:</b> HVTR++ is a virtual telepresence system that can be driven by poses and view images and render human avatars using <a href="https://taohuumd.github.io/projects/hvtr/" target=&ldquo;blank&rdquo;>Hybrid Volumetric-Textural Rendering (HVTR)</a>.
        </h2>

        <iframe width="900" height="506" src="https://www.youtube.com/embed/LE0-YpbLlkY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

        <iframe width="900" height="506" src="https://www.youtube.com/embed/RdKLfRYtg3I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

      </div>
    </div>    

</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="font-size: 14pt;">
            Recent neural rendering methods have made great progress in generating photorealistic human avatars. However, these methods are generally conditioned only on low-dimensional driving signals (e.g., body poses), which are insufficient to encode the complete appearance of a clothed human. Hence they fail to generate faithful details. To address this problem, we exploit driving view images (e.g., in telepresence systems) as additional inputs. We propose a novel neural rendering pipeline, Hybrid Volumetric-Textural Rendering (HVTR++), which synthesizes 3D human avatars from arbitrary driving poses and views while staying faithful to appearance details efficiently and at high quality. First, we learn to encode the driving signals of pose and view image on a dense UV manifold of the human body surface and extract UV-aligned features, preserving the structure of a skeleton-based parametric model. To handle complicated motions (e.g., self-occlusions), we then leverage the UV-aligned features to construct a 3D volumetric representation based on a dynamic neural radiance field. While this allows us to represent 3D geometry with changing topology, volumetric rendering is computationally heavy. Hence we employ only a rough volumetric representation using a pose- and image-conditioned downsampled neural radiance field (PID-NeRF), which we can render efficiently at low resolutions. In addition, we learn 2D textural features that are fused with rendered volumetric features in image space. The key advantage of our approach is that we can then convert the fused features into a high-resolution, high-quality avatar by a fast GAN-based textural renderer. We demonstrate that hybrid rendering enables HVTR++ to handle complicated motions, render high-quality avatars under user-controlled poses/shapes, and most importantly, be efficient at inference time. Our experimental results also demonstrate state-of-the-art quantitative results.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-centered", id="div1">
          <img src="static/data/overview.png">
          <div class="content has-text-justified">
          <p style="font-size: 13pt;">
          Taking as input the driving signals including multiple driving views with a fitted coarse SMPL mesh, and view direction, HVTR++ produces a full-body avatar. At the core of the pipeline is a <b>localised UV-aligned representation</b> which models both the geometric driving pose signals of a parametric mesh (SMPL) and sparse driving  image signals in a compact UV space. The UV-aligned representation can be efficiently rendered into images by <a href="https://taohuumd.github.io/projects/hvtr/" target=&ldquo;blank&rdquo;>Hybrid Volumetric-Textural Rendering</a>.
        </p>
        </div>
      </div>

      </div>
    </div>


    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Applications</h2>

        <div class="content has-text-justified">
          <p style="font-size: 13pt;">
			HVTR can render human avatars with both pose and shape control from arbitary viewpoints.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
				autoplay
                 controls
                 muted
                 preload
				 loop
                 width="100%">
            <source src="../hvtr/static/data/app_show.mp4"
                    type="video/mp4">
          </video>
        </div>


      </div>
    </div>
    <!--/ Animation. -->

	<div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Pose Driven Avatars</h2>
          <p>
            Render human avatars under different poses and viewpoints.
          </p>
          <video id="dollyzoom" controls muted loop playsinline height="100%">
            <source src="../hvtr/static/data/pose_driven.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-4">Shape Editing</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Render human avatars under different shape parameters.
            </p>
            <video id="matting-video" controls muted loop playsinline height="100%">
              <source src="../hvtr/static/data/shape_editing.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
	  </div>



  </div>

  <div>
  </br></br>
  </div>

  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@ARTICLE{hu2023hvtrpp,
  author={Hu, Tao and Xu, Hongyi and Luo, Linjie and Yu, Tao and Zheng, Zerong and Zhang, He and Liu, Yebin and Zwicker, Matthias},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={HVTR++: Image and Pose Driven Human Avatars using Hybrid Volumetric-Textural Rendering}, 
  year={2023}
}
@inproceedings{HVTR:3DV2022,
  title={HVTR: Hybrid Volumetric-Textural Rendering for Human Avatars},
  author={Hu, Tao and Yu, Tao and Zheng, Zerong and Zhang, He and Liu, Yebin and Zwicker, Matthias},
  booktitle = {2022 International Conference on 3D Vision (3DV)},
  year = {2022}
}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
		  For questions and clarifications please get in touch with: Tao Hu taohu[at]umd DOT edu. For the reproduction and performance of each baseline method please check our paper.
		  </p>
		  <p>
          The website template is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>. Thanks to the original authors.</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
